{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPV+S4/cseXiApsPvFn7n3X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moodenaresh1902/An-image-segmentation-method-for-the-physical-touching-soybean-seeds/blob/main/Soyabean_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R4Y2xfL6rPP"
      },
      "outputs": [],
      "source": [
        "#setting up the environment\n",
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "from sklearn.model_selection import train_test_split\n",
        "# DATA IMPORT\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "##preprocessing************************************************************************\n",
        "data = []\n",
        "paths = []\n",
        "result = []\n",
        "\n",
        "for r, d, f in os.walk(r'/content/drive/My Drive/AI/Soybean_Seeds'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (227,227,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[0]]).toarray())\n",
        "\n",
        "\n",
        "data = np.array(data)\n",
        "data.shape\n",
        "print(f'Total number of images we have: {len(data)}')\n",
        "result = np.array(result)\n",
        "result = result.reshape(1200,2)\n",
        "\n",
        "#Splitting the data into training and testing\n",
        "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)\n",
        "print(f'Number of images in training data: {len(x_train)}')\n",
        "print(f'Number of images in testing data: {len(x_test)}')\n",
        "\n",
        "#############Building the AI Model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(227, 227, 3), padding = 'Same'))\n",
        "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
        "\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
        "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax')\n",
        "print(model.summary())\n",
        "####################################33\n",
        "y_train.shape\n",
        "############Training#########################################33\n",
        "history = model.fit(x_train, y_train, epochs = 30, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))\n",
        "#############################################plotting losses####################33\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Test', 'Validation'], loc='upper right')\n",
        "plt.show()\n",
        "###################Testing the model##############################333\n",
        "def names(number):\n",
        "    if number==0:\n",
        "        return 'Soyabean found'\n",
        "    else:\n",
        "        return 'No Soyabean in the image'\n",
        "###########################\n",
        "from matplotlib.pyplot import imshow\n",
        "img = Image.open(r\"/content/drive/My Drive/AI/validation/groundnut.jpg\")\n",
        "x = np.array(img.resize((227,227)))\n",
        "x = x.reshape(1,227,227,3)\n",
        "res = model.predict_on_batch(x)\n",
        "classification = np.where(res == np.amax(res))[1][0]\n",
        "imshow(img)\n",
        "print(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))\n",
        "###########################################\n",
        "from matplotlib.pyplot import imshow\n",
        "img = Image.open(r\"/content/drive/My Drive/AI/validation/1201.jpg\")\n",
        "x = np.array(img.resize((128,128)))\n",
        "x = x.reshape(1,128,128,3)\n",
        "res = model.predict_on_batch(x)\n",
        "classification = np.where(res == np.amax(res))[1][0]\n",
        "imshow(img)\n",
        "print(str(res[0][classification]*100) + '% Confidence This Is A ' + names(classification))"
      ]
    }
  ]
}